{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI525: Web and Cloud Computing\n",
    "\n",
    "## Milestone I: Tackling big data on your laptop\n",
    "\n",
    "*Authors (Group 3): Mitchie, Jianru, Aishwarya, Aditya*<br>\n",
    "*Date: April 4th, 2021*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "- [1. Downloading the data](#1.-Downloading-the-data-)\n",
    "- [2. Combine the data CSVs](#2.-Combine-the-data-CSVs)\n",
    "- [3. Load the combined CSV to memory and perform a simple EDA](#3.-Load-the-combined-CSV-to-memory-and-perform-a-simple-EDA)\n",
    "- [4. Perform a simple EDA in R](#4.-Perform-a-simple-EDA-in-R)\n",
    "- [5. Final Comments](#5.-Final-Comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dengj\\Miniconda3\\envs\\525\\lib\\site-packages\\rpy2\\robjects\\packages.py:366: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Jupyter lab cell extensions\n",
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Downloading the data <a name=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\dengj\\\\ubc_mds_21\\\\ds_block6\\\\525_web_cloud_comp\\\\majacloud\\\\notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dengj\\ubc_mds_21\\ds_block6\\525_web_cloud_comp\\majacloud\\notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\\\Users\\\\dengj\\\\ubc_mds_21\\\\ds_block6\\\\525_web_cloud_comp\\\\majacloud\\\\notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "article_id = 14096681 \n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figsharerainfall/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_link_only': False,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'id': 26579150,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'size': 58863},\n",
       " {'is_link_only': False,\n",
       "  'name': 'environment.yml',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'id': 26579171,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'size': 192},\n",
       " {'is_link_only': False,\n",
       "  'name': 'README.md',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'id': 26586554,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'size': 5422},\n",
       " {'is_link_only': False,\n",
       "  'name': 'data.zip',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'id': 26766812,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'size': 814041183},\n",
       " {'is_link_only': False,\n",
       "  'name': 'get_data.py',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'id': 26766815,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'size': 4113}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# get the file named data.zip\n",
    "files_to_dl = [\"data.zip\"]  \n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# extract the file\n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Combine the data CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Combine the data CSVs by `Pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>3.293256e-13</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>1.047658e-02</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  lat_min  lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "0  1889-01-01 12:00:00   -36.25    -35.0  140.625    142.5   3.293256e-13   \n",
       "1  1889-01-02 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "2  1889-01-03 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "3  1889-01-04 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "4  1889-01-05 12:00:00   -36.25    -35.0  140.625    142.5   1.047658e-02   \n",
       "\n",
       "        model  \n",
       "0  ACCESS-CM2  \n",
       "1  ACCESS-CM2  \n",
       "2  ACCESS-CM2  \n",
       "3  ACCESS-CM2  \n",
       "4  ACCESS-CM2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get an idea how individual file looks like \n",
    "use_cols = [\"time\", \"lat_min\", \"lat_max\", \"lon_min\",\"lon_max\", \"rain (mm/day)\"]\n",
    "df1 = pd.read_csv(\"figsharerainfall/ACCESS-CM2_daily_rainfall_NSW.csv\", usecols=use_cols,dtype={'TailNum': 'str'})\n",
    "df1['model'] = \"ACCESS-CM2\"\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_combined_filepath = \"figsharerainfall/combined_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 491.90 MiB, increment: 0.12 MiB\n",
      "The pandas data frame has been concatenated!\n",
      "The combined data is saved in figsharerainfall/combined_data.csv\n",
      "Wall time: 10min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "# Shows time that regular python takes to merge file\n",
    "# Join all data together using pandas\n",
    "files = glob.glob('figsharerainfall\\*_daily_rainfall_NSW.csv')\n",
    "df = pd.concat((pd.read_csv(file, index_col=0, usecols=use_cols)\n",
    "                .assign(model=re.findall(r'[^\\\\]+(?=\\_d)', file)[0])\n",
    "                for file in files)\n",
    "              )\n",
    "\n",
    "# df = pd.concat((pd.read_csv(file, index_col=0, usecols=use_cols)\n",
    "#                 .assign(model=re.findall(r'[^\\\\]+(?=\\_d)', file)[0])\n",
    "#                 for file in files)\n",
    "#               )\n",
    "\n",
    "print('The pandas data frame has been concatenated!')\n",
    "\n",
    "\n",
    "df.to_csv(\"figsharerainfall/combined_data.csv\")\n",
    "\n",
    "print(f\"The combined data is saved in {out_combined_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7G\tfigsharerainfall/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh figsharerainfall/combined_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(out_combined_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62467843, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>3.293256e-13</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>1.047658e-02</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  lat_min  lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "0  1889-01-01 12:00:00   -36.25    -35.0  140.625    142.5   3.293256e-13   \n",
       "1  1889-01-02 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "2  1889-01-03 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "3  1889-01-04 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "4  1889-01-05 12:00:00   -36.25    -35.0  140.625    142.5   1.047658e-02   \n",
       "\n",
       "        model  \n",
       "0  ACCESS-CM2  \n",
       "1  ACCESS-CM2  \n",
       "2  ACCESS-CM2  \n",
       "3  ACCESS-CM2  \n",
       "4  ACCESS-CM2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Combine the data CSV by `dask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay dask combining to csv is done, and u can find the file here figsharerainfall/combined_data_dask.csv\n",
      "peak memory: 3164.26 MiB, increment: 1989.64 MiB\n",
      "Wall time: 8min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# show time that dask take to merge\n",
    "\n",
    "ddf = dd.read_csv(\"figsharerainfall/*_daily_rainfall_NSW.csv\", usecols=use_cols, assume_missing=True)\n",
    "\n",
    "out_ddf_filepath = \"figsharerainfall/combined_data_dask.csv\"\n",
    "ddf.to_csv(out_ddf_filepath, single_file=True)\n",
    "\n",
    "print(f\"Yay dask combining to csv is done, and u can find the file here {out_ddf_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 6 entries, time to rain (mm/day)\n",
      "dtypes: object(1), float64(5)"
     ]
    }
   ],
   "source": [
    "ddf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Summary of observations on run-time and memory usages in both options (THIS IS A DRAFT TO HAVE EVERYONE'S INPUT AND MAY COMPILE LATER)\n",
    "Compare run times and memory usages of these options on different machines within your team, and summarize your observations in your milestone notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mitchie:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jianru: The runtime and memory usages can vary by the type of machines and operation systems, but relatively long time and fairly large memory are required for such big-sized data. `Dask` for loading and writing data is relatively faster than `Pandas`, due to the fact that `Dask` reads data in chunks and parallel. Overall, compiling such big data into one csv file and load it every single time is not suggested, and alternatively file type should be considered such as `feather`or `parquet`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aishwarya:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aditya:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall, TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the combined CSV to memory and perform a simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           ACCESS-CM2\n",
       "1           ACCESS-CM2\n",
       "2           ACCESS-CM2\n",
       "3           ACCESS-CM2\n",
       "4           ACCESS-CM2\n",
       "               ...    \n",
       "62467838       TaiESM1\n",
       "62467839       TaiESM1\n",
       "62467840       TaiESM1\n",
       "62467841       TaiESM1\n",
       "62467842       TaiESM1\n",
       "Name: model, Length: 62467843, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load only the interested columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "NorESM2-MM          3541230\n",
      "TaiESM1             3541230\n",
      "CMCC-ESM2           3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "SAM0-UNICON         3541153\n",
      "GFDL-CM4            3219300\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-ESM4           3219300\n",
      "MRI-ESM2-0          3037320\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-LR        966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "CanESM5              551880\n",
      "BCC-ESM1             551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 1054.27 MiB, increment: 954.12 MiB\n",
      "Wall time: 59.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "#48s\n",
    "\n",
    "data_model = pd.read_csv(out_combined_filepath, usecols=['model'])\n",
    "print(data_model.model.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Change `dtype` of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f64_mem = df.iloc[:, 1:6].memory_usage().sum()/1e6\n",
    "f32_mem = df.iloc[:, 1:6].astype('float32', errors='ignore').memory_usage().sum() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with float64:  2498.71 MB\n",
      "Memory usage with float32:  1249.36 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with float64: {f64_mem: .2f} MB\")\n",
    "print(f\"Memory usage with float32: {f32_mem: .2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Load in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int32\n",
      "peak memory: 2827.38 MiB, increment: 2160.73 MiB\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# 4min\n",
    "# example of how to load data in small chunks. We can pass chunksize as a parameter while using read_csv.\n",
    "\n",
    "model_counts = pd.Series(dtype=int)\n",
    "\n",
    "for chunk in pd.read_csv('figsharerainfall/combined_data.csv', chunksize = 10_000_000):\n",
    "    model_counts = model_counts.add(chunk['model'].value_counts(), fill_value = 0)\n",
    "print(model_counts.astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jianru py EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Load the entire data using `dask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 1997.25 MiB, increment: 1497.16 MiB\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# 55s\n",
    "ddf = dd.read_csv(out_combined_filepath)\n",
    "print(ddf.model.value_counts().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Discussion of the observations on those approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mitchie:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jianru: When only a certain columns are loaded, it takes shorter time to run for around 60s. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aishwarya:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aditya:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall, TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aditya R EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 (One approach to transfer df from py to R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Discussion on why you choose this approach over the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mitchie:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jianru: As the input data size is around 5.7GB, I would be extremely slow using `Pandas` exchange, so it's not considered. For `Parquet` file, it could have svaed more storage space, but this might not be the main concern here as the data size is manageable so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aishwarya:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aditya:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall, TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
